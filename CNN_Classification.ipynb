{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport math","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\ntrain_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\ntest_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Display sample images","metadata":{}},{"cell_type":"code","source":"image, label = train_dataset[0]\nprint(image.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 5, figsize=(10, 15))\n\nfor i in range(5):\n    image, label = train_dataset[i]\n\n    axes[i].imshow(image.squeeze(), cmap='gray')\n    axes[i].set_title(f\"Label: {label}\")\n\nplt.tight_layout()\nplt.grid(False)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class MyModel(nn.Module):\n    def __init__(self, input_size, channels, num_classes):\n        super(MyModel, self).__init__()\n\n        self.input_size = input_size\n        self.channels = channels\n        self.num_classes = num_classes\n\n        # layer 1\n        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n        # self.relu1 = nn.ReLU()\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        # layer 2\n        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n        # self.relu2 = nn.ReLU()\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        # layer 3\n        self.cnn3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n        # self.relu3 = nn.ReLU()\n\n\n        # output layer\n        self.linear = nn.Linear(64* (self.input_size // 4) * (self.input_size // 4), self.num_classes)\n        # self.softmax = nn.Softmax(dim=-1)\n\n    def forward(self, x):\n        x = self.cnn1(x)\n        # x = self.relu1(x)\n        x = self.pool1(x)\n        x = self.cnn2(x)\n        # x = self.relu2(x)\n        x = self.pool2(x)\n        x = self.cnn3(x)\n        # x = self.relu3(x)\n\n        x = x.view(-1, 64* (self.input_size // 4) * (self.input_size // 4))       \n        x = self.linear(x)\n        # x = self.softmax(x)\n\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"channels = 1\ninput_size = 28\nnum_classes = 10\n\nmodel = MyModel(input_size=input_size, channels=channels, num_classes=num_classes)\nimage, label = train_dataset[0]\n\npredicted = model(image)\n\nplt.imshow(image.squeeze(), cmap='gray')\nplt.title(f\"{label}\")\nplt.show()\n\nprint(f\"Predicted {predicted}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_epochs = 10\nlearning_rate = 1e-4\n\nmodel = model.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\n\ntraining_losses = []\ntraining_accuracies = []\ntraining_f1_scores = []\n\ntest_losses = []\ntest_accuracies = []\ntest_f1_scores = []\n\n\nfor epoch in range(num_epochs):\n\n    model.train()\n    train_loss = 0.0\n    train_preds = []\n    train_labels = []\n\n    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n    for images, labels in progress_bar:\n        images = images.float().to(device)\n        labels = labels.long().to(device)\n\n        predicted_logits = model(images)\n        # predicted_labels = torch.argmax(predicted_logits)\n\n        loss = criterion(predicted_logits, labels)\n        loss.backward()\n        optimizer.step()\n\n        progress_bar.set_postfix(loss=loss.item())\n        train_loss += loss.item() * images.size(0)\n\n        preds = torch.argmax(predicted_logits, dim=1)\n        train_preds.extend(preds.cpu().numpy())\n        train_labels.extend(labels.cpu().numpy())\n\n    avg_train_loss = train_loss / len(train_loader.dataset)\n    train_acc = accuracy_score(train_labels, train_preds)\n    train_f1 = f1_score(train_labels, train_preds, average='weighted')\n\n    training_losses.append(avg_train_loss)\n    training_accuracies.append(train_acc)\n    training_f1_scores.append(train_f1)\n\n    # Evaluation\n    model.eval()\n    test_loss = 0.0\n    test_preds = []\n    test_labels = []\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images = images.to(device).float()\n            labels = labels.to(device).long()\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            test_loss += loss.item() * images.size(0)\n\n            preds = torch.argmax(outputs, dim=1)\n            test_preds.extend(preds.cpu().numpy())\n            test_labels.extend(labels.cpu().numpy())\n\n    avg_test_loss = test_loss / len(test_loader.dataset)\n    test_acc = accuracy_score(test_labels, test_preds)\n    test_f1 = f1_score(test_labels, test_preds, average='weighted')\n\n    test_losses.append(avg_test_loss)\n    test_accuracies.append(test_acc)\n    test_f1_scores.append(test_f1)\n\n    print(f\"\\nEpoch {epoch+1}/{num_epochs} Summary:\")\n    print(f\"Train Loss: {avg_train_loss:.4f} | Acc: {train_acc:.4f} | F1: {train_f1:.4f}\")\n    print(f\"Test  Loss: {avg_test_loss:.4f} | Acc: {test_acc:.4f} | F1: {test_f1:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), 'model_weights.pth')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scores = ['losses', 'accuracies', 'f1_scores']\n\nfor index, score in enumerate(scores):\n    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n\n    if score == 'losses':\n        axes[0].plot(training_losses)\n        axes[1].plot(test_losses)\n    elif score == 'accuracies':\n        axes[0].plot(training_accuracies)\n        axes[1].plot(test_accuracies)\n    else:\n        axes[0].plot(training_f1_scores)\n        axes[1].plot(test_f1_scores)\n\n    axes[0].set_title(f\"Training {score}\")\n    axes[1].set_title(f\"Testing {score}\")\n\n    plt.show()\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Checking whats in the intermediate levels","metadata":{}},{"cell_type":"code","source":"# for name, param in model.named_parameters():\n#     if 'weight' in name:\n#         print(f\"Layer: {name}, Shape: {param.shape}\")\n#         # print(param.data)\n\n#         sp = int(math.sqrt(param.shape[0]))\n#         fig, axes = plt.subplots(sp, sp, figsize=(10, 15))\n\n#         for index, d in enumerate(param.data):\n#             row = index // sp\n#             col = index % sp\n            \n#             axes[row, col].imshow(d.cpu().numpy().squeeze(), cmap='gray')\n#         plt.show()    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}