{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a2d869b",
   "metadata": {
    "papermill": {
     "duration": 0.003272,
     "end_time": "2025-08-17T03:09:34.667471",
     "exception": false,
     "start_time": "2025-08-17T03:09:34.664199",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Basic Definitions\n",
    "## Corpus\n",
    "Collection of all words in a dataset, when whole dataset is concatenated.\n",
    "\n",
    "## Vocabulary\n",
    "Collection of all unique words from the corpus.\n",
    "\n",
    "## Document\n",
    "A single instance of the dataset. In this case, a single review.\n",
    "\n",
    "## word\n",
    "single word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527d69c8",
   "metadata": {
    "papermill": {
     "duration": 0.002364,
     "end_time": "2025-08-17T03:09:34.672953",
     "exception": false,
     "start_time": "2025-08-17T03:09:34.670589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "090c981e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T03:09:34.679594Z",
     "iopub.status.busy": "2025-08-17T03:09:34.679262Z",
     "iopub.status.idle": "2025-08-17T03:09:40.265829Z",
     "shell.execute_reply": "2025-08-17T03:09:40.264685Z"
    },
    "papermill": {
     "duration": 5.592359,
     "end_time": "2025-08-17T03:09:40.267899",
     "exception": false,
     "start_time": "2025-08-17T03:09:34.675540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspellchecker\r\n",
      "  Downloading pyspellchecker-0.8.3-py3-none-any.whl.metadata (9.5 kB)\r\n",
      "Downloading pyspellchecker-0.8.3-py3-none-any.whl (7.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pyspellchecker\r\n",
      "Successfully installed pyspellchecker-0.8.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f8a51d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T03:09:40.276371Z",
     "iopub.status.busy": "2025-08-17T03:09:40.276025Z",
     "iopub.status.idle": "2025-08-17T03:09:52.491093Z",
     "shell.execute_reply": "2025-08-17T03:09:52.490181Z"
    },
    "papermill": {
     "duration": 12.221486,
     "end_time": "2025-08-17T03:09:52.492898",
     "exception": false,
     "start_time": "2025-08-17T03:09:40.271412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fec43d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T03:09:52.501382Z",
     "iopub.status.busy": "2025-08-17T03:09:52.500424Z",
     "iopub.status.idle": "2025-08-17T03:09:53.328346Z",
     "shell.execute_reply": "2025-08-17T03:09:53.327502Z"
    },
    "papermill": {
     "duration": 0.833632,
     "end_time": "2025-08-17T03:09:53.329967",
     "exception": false,
     "start_time": "2025-08-17T03:09:52.496335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10409</th>\n",
       "      <td>This, I think, is one of the best pictures eve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6542</th>\n",
       "      <td>It's a little disconcerting to have a characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6003</th>\n",
       "      <td>This tear-teaser, written by Steve Martin hims...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8117</th>\n",
       "      <td>One of my all time favourite films, ever. Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17704</th>\n",
       "      <td>Another fun, witty, frothy RKO musical with As...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "10409  This, I think, is one of the best pictures eve...      0\n",
       "6542   It's a little disconcerting to have a characte...      0\n",
       "6003   This tear-teaser, written by Steve Martin hims...      1\n",
       "8117   One of my all time favourite films, ever. Just...      0\n",
       "17704  Another fun, witty, frothy RKO musical with As...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/imdb-reviews/reviews.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bf8277",
   "metadata": {
    "papermill": {
     "duration": 0.002896,
     "end_time": "2025-08-17T03:09:53.336464",
     "exception": false,
     "start_time": "2025-08-17T03:09:53.333568",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d69ee1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T03:09:53.344221Z",
     "iopub.status.busy": "2025-08-17T03:09:53.343899Z",
     "iopub.status.idle": "2025-08-17T03:09:53.349719Z",
     "shell.execute_reply": "2025-08-17T03:09:53.348807Z"
    },
    "papermill": {
     "duration": 0.011672,
     "end_time": "2025-08-17T03:09:53.351329",
     "exception": false,
     "start_time": "2025-08-17T03:09:53.339657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_punc = string.punctuation\n",
    "all_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1458356c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T03:09:53.359554Z",
     "iopub.status.busy": "2025-08-17T03:09:53.358921Z",
     "iopub.status.idle": "2025-08-17T03:09:54.278726Z",
     "shell.execute_reply": "2025-08-17T03:09:54.277651Z"
    },
    "papermill": {
     "duration": 0.925723,
     "end_time": "2025-08-17T03:09:54.280476",
     "exception": false,
     "start_time": "2025-08-17T03:09:53.354753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\", \"textcat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "823e1a35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T03:09:54.289149Z",
     "iopub.status.busy": "2025-08-17T03:09:54.288540Z",
     "iopub.status.idle": "2025-08-17T03:09:54.486139Z",
     "shell.execute_reply": "2025-08-17T03:09:54.485025Z"
    },
    "papermill": {
     "duration": 0.203634,
     "end_time": "2025-08-17T03:09:54.487677",
     "exception": false,
     "start_time": "2025-08-17T03:09:54.284043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['enjoy', 'movie', 'lot', 'fan', 'whoop', 'goldberg', 'movie', 'emphasize', 'portray', 'housewife', 'african', 'american', 'family', 'move', 'social', 'chain', 'husband', 's', 'danny', 'glover', 'success', 'attorney', 'move', 'white', 'neighborhood', 'people', 'friendly', 'little', 'awkward', 'event', 'arise', 'course', 'movie', 'laugh', 'appeal', 'emotion', 'movie', 'comedy', 'drama', 'strong', 'highly', 'recommend', 'catch', 'rent', 'soon']\n"
     ]
    }
   ],
   "source": [
    "# clearning\n",
    "# def clean_data(text):\n",
    "#     # lowercasing\n",
    "#     text = text.lower()\n",
    "\n",
    "#     # html tags\n",
    "#     text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "#     # urls\n",
    "#     text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "#     # punctuations\n",
    "#     text = text.translate(str.maketrans('', '', all_punc))\n",
    "\n",
    "#     # don't require chat word treatment\n",
    "#     # spelling correction\n",
    "#     blob = TextBlob(text)\n",
    "#     text = str(blob.correct())\n",
    "\n",
    "#     # skemming / lemmatization, I will be using lemmatization slower but accurate\n",
    "#     # tokenization + removing stop words + lemmatization\n",
    "#     doc = nlp(text)\n",
    "#     text = [w.lemma_ for w in doc if not w.is_stop]\n",
    "\n",
    "#     # no need to handle emojis\n",
    "\n",
    "#     return text\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "# precompiled regex\n",
    "CLEAN_RE = re.compile(r\"<.*?>|https?://\\S+|www\\.\\S+|[^a-zA-Z\\s]\")\n",
    "\n",
    "def clean_data(text):\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove html, urls, and punctuations in one go\n",
    "    text = CLEAN_RE.sub(\" \", text)\n",
    "\n",
    "    # optional: fast spell correction (way faster than TextBlob)\n",
    "    words = text.split()\n",
    "    corrected = [spell.correction(w) or w for w in words]\n",
    "    text = \" \".join(corrected)\n",
    "\n",
    "    # spacy pipeline: tokenization + stopword removal + lemmatization\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc if not token.is_stop and token.lemma_.strip()]\n",
    "\n",
    "sent = df['text'][0]\n",
    "# sent = '<h1>This is me </h1>'\n",
    "# sent = 'www.abc.com'\n",
    "# sent = 'I am a god playr'\n",
    "print(clean_data(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0e31d9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T03:09:54.496435Z",
     "iopub.status.busy": "2025-08-17T03:09:54.496136Z",
     "iopub.status.idle": "2025-08-17T10:07:32.913542Z",
     "shell.execute_reply": "2025-08-17T10:07:32.911978Z"
    },
    "papermill": {
     "duration": 25058.426662,
     "end_time": "2025-08-17T10:07:32.918314",
     "exception": false,
     "start_time": "2025-08-17T03:09:54.491652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14755    [hal, hartley, s, henry, fool, independent, fi...\n",
       "23975    [laughter, state, mind, say, tag, hesitate, co...\n",
       "19688    [stop, watch, lose, episode, think, ana, lucia...\n",
       "16787    [terry, west, good, idea, w, movie, t, flesh, ...\n",
       "18156    [imagining, tarzan, era, soloflex, apocalypse,...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(clean_data)\n",
    "df['text'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acf11cd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T10:07:32.927448Z",
     "iopub.status.busy": "2025-08-17T10:07:32.927047Z",
     "iopub.status.idle": "2025-08-17T10:07:34.212884Z",
     "shell.execute_reply": "2025-08-17T10:07:34.211830Z"
    },
    "papermill": {
     "duration": 1.292591,
     "end_time": "2025-08-17T10:07:34.214619",
     "exception": false,
     "start_time": "2025-08-17T10:07:32.922028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('pre_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84a6eba",
   "metadata": {
    "papermill": {
     "duration": 0.003384,
     "end_time": "2025-08-17T10:07:34.222188",
     "exception": false,
     "start_time": "2025-08-17T10:07:34.218804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Text Representation\n",
    "## Popular method\n",
    "* One-Hot-Encoding : Easy to implement but have many problems\n",
    "* Bag-of-Words : A better approach which solve many problems related to One-Hot-Encoder\n",
    "* N-Grams : Superset of BOW, instead of one word at a time, takes N words.\n",
    "* TF-IDF : Alternative to BOW, preservs a better semantic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9d004d",
   "metadata": {
    "papermill": {
     "duration": 0.003771,
     "end_time": "2025-08-17T10:07:34.229511",
     "exception": false,
     "start_time": "2025-08-17T10:07:34.225740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8062256,
     "sourceId": 12753488,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25088.815182,
   "end_time": "2025-08-17T10:07:37.230995",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-17T03:09:28.415813",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
