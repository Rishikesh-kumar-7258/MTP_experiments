{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nimport math","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T22:26:21.022983Z","iopub.execute_input":"2025-05-20T22:26:21.023287Z","iopub.status.idle":"2025-05-20T22:26:21.029224Z","shell.execute_reply.started":"2025-05-20T22:26:21.023265Z","shell.execute_reply":"2025-05-20T22:26:21.027847Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Step 1: Convert text into embeddings","metadata":{}},{"cell_type":"code","source":"text = \"Hello! How are you?\"\nprint(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T22:09:42.591461Z","iopub.execute_input":"2025-05-20T22:09:42.591723Z","iopub.status.idle":"2025-05-20T22:09:42.603728Z","shell.execute_reply.started":"2025-05-20T22:09:42.591698Z","shell.execute_reply":"2025-05-20T22:09:42.602540Z"}},"outputs":[{"name":"stdout","text":"Hello! How you are ?\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Transformer Model Implementation","metadata":{}},{"cell_type":"markdown","source":"### Positional Encoding ","metadata":{}},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self):\n        super(PositionalEncoding, self).__init__() # skip the positionalEncoding inside super (after python 3)\n\n\n    def forward(self, x):\n        max_words, d_model = x.shape\n        \n        matrix = torch.zeros(max_words, d_model)\n        two_i = 10000 ** (torch.arange(0, d_model, 2) / d_model)\n        pos = torch.arange(0, max_words)\n\n        matrix[:, 0::2] = torch.sin(pos / two_i)\n        matrix[:, 1::2] = torch.cos(pos / two_i)\n        \n        x += matrix\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T22:40:06.711028Z","iopub.execute_input":"2025-05-20T22:40:06.711396Z","iopub.status.idle":"2025-05-20T22:40:06.717820Z","shell.execute_reply.started":"2025-05-20T22:40:06.711371Z","shell.execute_reply":"2025-05-20T22:40:06.716695Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"### Self attention block","metadata":{}},{"cell_type":"code","source":"class SelfAttention(nn.Module):\n    def __init__(self):\n        super(SelfAttention, self).__init__()\n\n    def forward(x);\n\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MyTransformer(nn.Module):\n    def __init__(self, max_words, d_model):\n        super(MyTransformer, self).__init__()\n        \n        # embedding layer\n        self.embedding_layer = nn.Embedding(max_words, d_model)\n\n        # positional encoding\n        self.positional_encoding = PositionalEncoding()\n\n    def forward(self, x):\n        x = self.embedding_layer(x)\n        \n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"matrix = torch.zeros(5, 6)\nprint(matrix)\n\n# two_i = 10000 ** (torch.arange(0, 10, 2) / 10)\n# print(two_i)\n\n# pos = torch.arange(50)\n# print(pos)\n\n# print(torch.sin(pos / 10000))\n\na, b = matrix.shape\nprint(a, b)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T22:35:18.405592Z","iopub.execute_input":"2025-05-20T22:35:18.405880Z","iopub.status.idle":"2025-05-20T22:35:18.413557Z","shell.execute_reply.started":"2025-05-20T22:35:18.405860Z","shell.execute_reply":"2025-05-20T22:35:18.412695Z"}},"outputs":[{"name":"stdout","text":"tensor([[0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0.]])\n5 6\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}